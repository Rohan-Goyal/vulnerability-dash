
# Table of Contents

1.  [Spec](#orgd36b7fb)
    1.  [Problem Statement](#org472479f)
    2.  [References](#orgfe64ff8)
    3.  [Deliverables](#orgffa2d8c)
2.  [Process Outline](#orgb789594)
    1.  [Retrieving Data](#org6d4a92b)
    2.  [Structuring/Processing Data](#org3ab8a0f)
    3.  [Presenting](#orgf12d18c)
    4.  [Features/Bells and Whistles](#org91ff48b)
3.  [Data Presented](#org4a3790d)
        1.  [Abstract/High-Level/Overview](#orgf30ba5c)
        2.  [For individual vulnerabilities](#org3abe24b)
        3.  [Fixes/Recommendations/Action Items](#orge8a5b91)
4.  [Algorithms](#org42b55a8)
        1.  [Overall Flow (User-facing)](#org553f57d)
        2.  [Computations: Aggregation, overall scoring](#org71b160b)
5.  [Considering choices of frontend](#org56db681)



<a id="orgd36b7fb"></a>

# Spec


<a id="org472479f"></a>

## Problem Statement

Create a consolidated dashboard of vulnerabilities which could be present in the codebase. The vulnerabilities can be fetched by enabling Dependabot in Github and connecting the Github account to a Synk account. Please make sure that the Github account has code repositories.


<a id="orgfe64ff8"></a>

## References

-   <https://snyk.io>
-   <https://docs.github.com/en/code-security/dependabot/dependabot-security-updates/configuring-dependabot-security-updates>


<a id="orgffa2d8c"></a>

## Deliverables

1.  Please create a writeup on the approach and technologies being used to achieve the above.
2.  Please share the code repository once implemented.


<a id="orgb789594"></a>

# Process Outline

-   Write as much of it in Python as possible.


<a id="org6d4a92b"></a>

## Retrieving Data

-   Lookup API docs, and go through the setup.
-   Run quick experiments in Postman to get a sense of pitfalls/quirks, and the structure of returned data.
-   Build API requests that get a superset of the data I need, use PyGithub and Pysnyk to handle the actual API calls.
-   Collect JSON stubs for project vulnerabilities, save them as files to use as a supplementary data source (to get around the API restrictions)


<a id="org3ab8a0f"></a>

## Structuring/Processing Data

-   Choose which fields I want to keep, and which to discard (this is a design decision which may change over time, so make it as easy as possible to change)
-   Turn each vulnerability into a discrete JSON object associated with a project, rather than having a project associated with a list of vulnerabilities
-   Utility functions for pulling out that data from a messy nested JSON.
-   Translate data into intermediate format if required (eg: Mapping severity labels to integers, handling URLs/references)
-   Generate processed data, such as any aggregation I want to run.


<a id="orgf12d18c"></a>

## Presenting

-   Options for frontend are web page or DB in Notion (based on my proficiencies/experiences)
-   Notion seems the strongest, since it has a sophisticated API, can be used as a bug tracker for projects, and it means we get a nice UI + search and filter tools for free.


<a id="org91ff48b"></a>

## Features/Bells and Whistles

-   Export summary as JSON via CLI


<a id="org4a3790d"></a>

# Data Presented


<a id="orgf30ba5c"></a>

### Abstract/High-Level/Overview

-   Count, broken down by repo
-   Aggregate stats: Number of vulnerabilities, averages of everything we can average.
-   Overall color and grade based on number and severity of vulnerabilities.


<a id="org3abe24b"></a>

### For individual vulnerabilities

-   Project name and repo link
-   Location: Source file, line number
-   Severity color
-   Summary of issue (first sentence)
-   Either package name or line number, depending on type of vulnerability
-   Status: Handled, dismissed, open.
-   Date discovered/updated
-   CVE/GHSA link, if applicable


<a id="orge8a5b91"></a>

### Fixes/Recommendations/Action Items

-   This is something like a separate tab from the main view.
-   Only for open vulnerabilities (obviously).
-   Packages and the fixed version number to update to.
-   For Snyk, try to pull that info from the site or JSON stubs.
-   Link to learn.snyk.io?


<a id="org42b55a8"></a>

# Algorithms


<a id="org553f57d"></a>

### Overall Flow (User-facing)

-   We have a list of repositories hardcoded/from file
-   Retrieve all relevant data, store in intermediate format (processing+aggregation, etc.)
-   Construct a Notion database from the intermediate representation on a preselected notion page.
-   Add vulnerabilities to the DB as elems.
-   User selects a repository or applies filters (via the Notion UI)
-   User can run the app via CLI to rebuild the DB. Or option to make it a regular thing, like a cron job or a button for it in the UI.


<a id="org71b160b"></a>

### Computations: Aggregation, overall scoring

-   This is largely ad-hoc. Log-scale roughly, so a grade N vuln has score $2^N$, or so. Make this flexible, so don&rsquo;t hardcode the specific scoring mechanism.
-   Present this &ldquo;weighted sum&rdquo;, grade it somewhat arbitrarily.
-   Average number and severity (per-repo, and for the entire set)


<a id="org56db681"></a>

# Considering choices of frontend

-   NOTE: This section is mostly just me thinking out loud
-   Web feels the most natural, given my experience.
-   Reuse an idea I&rsquo;ve used before: Local webpage. So basically use a python script to generate a webpage dynamically and serve it over localhost.
-   An alternative would be to do something more sophisticated with a JS frontend, but this is more of a \`stretch goal&rsquo;, depending on how long it takes me to get the data.
-   Programatically constructed Notion.so page? This is possible, but requires recomputing every time. Which is honestly fine. Notion is basically a cheap database with a builtin frontend, there are worse things to use for this.
-   <https://github.com/ramnes/notion-sdk-py/blob/main/examples/databases/create_database.py> shows how to create a notion DB based on python dictionaries as data, so that&rsquo;s at least feasible.
-   <https://dev.to/maeganwilson_/how-to-use-notion-as-an-issue-tracker-3oab> establishes that notion is definitely usable for sophisticated stuff like bug tracking.
-   Notion also has a &ldquo;notion.site&rdquo; option for turning notebooks into shareable webpages, so we can get all the good stuff of a webpage without actually writing any JS.
-   Notion formulas exist, so aggregation is possible even if the neat display is hard. Actually we can just do computations in python and share the aggregate data to notion, perhaps in a separate tab/view.
-   Notion DB also means we get search and filter for free.
-   So either a notion DB with aggregation (might be hard), or a classic python local webserver.
-   Confession: This is largely based on the fact that I&rsquo;ve wanted to explore the Notion API ever since it became public, and this is a good chance to do so.

